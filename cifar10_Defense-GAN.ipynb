{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from dataset import Adversarial_Dataset\n",
    "from utils import adjust_lr, get_z_sets, get_z_star, Resize_Image\n",
    "from model import CNN\n",
    "from gan_model import Generator,Discriminator,Decoder\n",
    "from torchsummary import summary\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "in_channel = 3\n",
    "height = 32\n",
    "width = 32\n",
    "\n",
    "display_steps = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "         LeakyReLU-3           [-1, 32, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          18,496\n",
      "         LeakyReLU-5           [-1, 64, 32, 32]               0\n",
      "         AvgPool2d-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-9          [-1, 128, 16, 16]               0\n",
      "           Conv2d-10          [-1, 128, 16, 16]         147,584\n",
      "        LeakyReLU-11          [-1, 128, 16, 16]               0\n",
      "        AvgPool2d-12            [-1, 128, 8, 8]               0\n",
      "           Conv2d-13            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "        LeakyReLU-15            [-1, 256, 8, 8]               0\n",
      "           Conv2d-16            [-1, 256, 8, 8]         590,080\n",
      "        LeakyReLU-17            [-1, 256, 8, 8]               0\n",
      "        AvgPool2d-18            [-1, 256, 4, 4]               0\n",
      "           Linear-19                 [-1, 1024]       4,195,328\n",
      "             ReLU-20                 [-1, 1024]               0\n",
      "           Linear-21                  [-1, 512]         524,800\n",
      "             ReLU-22                  [-1, 512]               0\n",
      "          Dropout-23                  [-1, 512]               0\n",
      "           Linear-24                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 5,852,170\n",
      "Trainable params: 5,852,170\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.87\n",
      "Params size (MB): 22.32\n",
      "Estimated Total Size (MB): 26.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model = CNN()\n",
    "\n",
    "summary(model, input_size = (in_channel,height,width), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_model = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./checkpoints/cifar10.pth'))\n",
    "\n",
    "model = model.to(device_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load defense-GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 10.0\n",
    "rec_iters = [800]\n",
    "rec_rrs = [20]\n",
    "decay_rate = 0.1\n",
    "global_step = 3.0\n",
    "generator_input_size = 32\n",
    "\n",
    "INPUT_LATENT = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_generator = torch.device(0)\n",
    "device_disc = torch.device(0)\n",
    "device_dec = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 4096]         266,240\n",
      "       BatchNorm1d-2                 [-1, 4096]           8,192\n",
      "              ReLU-3                 [-1, 4096]               0\n",
      "   ConvTranspose2d-4            [-1, 128, 8, 8]         131,200\n",
      "       BatchNorm2d-5            [-1, 128, 8, 8]             256\n",
      "              ReLU-6            [-1, 128, 8, 8]               0\n",
      "   ConvTranspose2d-7           [-1, 64, 16, 16]          32,832\n",
      "       BatchNorm2d-8           [-1, 64, 16, 16]             128\n",
      "              ReLU-9           [-1, 64, 16, 16]               0\n",
      "  ConvTranspose2d-10            [-1, 3, 32, 32]             771\n",
      "             Tanh-11            [-1, 3, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 439,619\n",
      "Trainable params: 439,619\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.70\n",
      "Params size (MB): 1.68\n",
      "Estimated Total Size (MB): 2.38\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           1,792\n",
      "         LeakyReLU-2           [-1, 64, 16, 16]               0\n",
      "            Conv2d-3            [-1, 128, 8, 8]          73,856\n",
      "         LeakyReLU-4            [-1, 128, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 4, 4]         295,168\n",
      "         LeakyReLU-6            [-1, 256, 4, 4]               0\n",
      "            Linear-7                    [-1, 1]           4,097\n",
      "================================================================\n",
      "Total params: 374,913\n",
      "Trainable params: 374,913\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.44\n",
      "Params size (MB): 1.43\n",
      "Estimated Total Size (MB): 1.88\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           1,792\n",
      "         LeakyReLU-2           [-1, 64, 16, 16]               0\n",
      "            Conv2d-3            [-1, 128, 8, 8]          73,856\n",
      "         LeakyReLU-4            [-1, 128, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 4, 4]         295,168\n",
      "         LeakyReLU-6            [-1, 256, 4, 4]               0\n",
      "            Linear-7                  [-1, 512]       2,097,664\n",
      "         LeakyReLU-8                  [-1, 512]               0\n",
      "            Linear-9                   [-1, 64]          32,832\n",
      "================================================================\n",
      "Total params: 2,501,312\n",
      "Trainable params: 2,501,312\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.45\n",
      "Params size (MB): 9.54\n",
      "Estimated Total Size (MB): 10.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ModelG = Generator()\n",
    "ModelD = Discriminator()\n",
    "Dec = Decoder()\n",
    "\n",
    "generator_path = './defensive_models/gen_cifar10_gp_61299.pth'\n",
    "disc_path = './defensive_models/disc_cifar10_gp_61299.pth'\n",
    "dec_path = './dec_checkpoints/cifar10_dec_100.pth'\n",
    "\n",
    "ModelG.load_state_dict(torch.load(generator_path))\n",
    "ModelD.load_state_dict(torch.load(disc_path))\n",
    "Dec.load_state_dict(torch.load(dec_path))\n",
    "\n",
    "summary(ModelG, input_size = (INPUT_LATENT,), device = 'cpu')\n",
    "summary(ModelD, input_size = (3, 32, 32), device = 'cpu')\n",
    "summary(Dec, input_size = (3, 32, 32), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelG = ModelG.to(device_generator)\n",
    "ModelD = ModelD.to(device_disc)\n",
    "Dec = Dec.to(device_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial dataset path\n",
    "root_dir = './adversarial/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_test)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size*2, shuffle=True, num_workers=4,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rec_saves = []\n",
    "img_inputs = []\n",
    "save_losses = []\n",
    "learning_rate = 1e-3\n",
    "criterion_dec = nn.MSELoss()\n",
    "optim_dec = optim.Adam(Dec.parameters(), lr=learning_rate, betas=(0.5, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  100] loss:0.133\n",
      "[1,  200] loss:0.108\n",
      "[1,  300] loss:0.102\n",
      "[1,  400] loss:0.097\n",
      "[1,  500] loss:0.095\n",
      "[1,  600] loss:0.093\n",
      "[1,  700] loss:0.092\n",
      "[2,  100] loss:0.090\n",
      "[2,  200] loss:0.089\n",
      "[2,  300] loss:0.090\n",
      "[2,  400] loss:0.088\n",
      "[2,  500] loss:0.087\n",
      "[2,  600] loss:0.087\n",
      "[2,  700] loss:0.088\n",
      "[3,  100] loss:0.086\n",
      "[3,  200] loss:0.086\n",
      "[3,  300] loss:0.086\n",
      "[3,  400] loss:0.084\n",
      "[3,  500] loss:0.084\n",
      "[3,  600] loss:0.085\n",
      "[3,  700] loss:0.084\n",
      "[4,  100] loss:0.083\n",
      "[4,  200] loss:0.083\n",
      "[4,  300] loss:0.084\n",
      "[4,  400] loss:0.083\n",
      "[4,  500] loss:0.082\n",
      "[4,  600] loss:0.084\n",
      "[4,  700] loss:0.083\n",
      "[5,  100] loss:0.082\n",
      "[5,  200] loss:0.083\n",
      "[5,  300] loss:0.082\n",
      "[5,  400] loss:0.082\n",
      "[5,  500] loss:0.081\n",
      "[5,  600] loss:0.082\n",
      "[5,  700] loss:0.081\n",
      "[6,  100] loss:0.081\n",
      "[6,  200] loss:0.080\n",
      "[6,  300] loss:0.080\n",
      "[6,  400] loss:0.081\n",
      "[6,  500] loss:0.081\n",
      "[6,  600] loss:0.081\n",
      "[6,  700] loss:0.079\n",
      "[7,  100] loss:0.080\n",
      "[7,  200] loss:0.081\n",
      "[7,  300] loss:0.079\n",
      "[7,  400] loss:0.080\n",
      "[7,  500] loss:0.078\n",
      "[7,  600] loss:0.080\n",
      "[7,  700] loss:0.080\n",
      "[8,  100] loss:0.079\n",
      "[8,  200] loss:0.080\n",
      "[8,  300] loss:0.079\n",
      "[8,  400] loss:0.078\n",
      "[8,  500] loss:0.078\n",
      "[8,  600] loss:0.078\n",
      "[8,  700] loss:0.078\n",
      "[9,  100] loss:0.078\n",
      "[9,  200] loss:0.078\n",
      "[9,  300] loss:0.078\n",
      "[9,  400] loss:0.078\n",
      "[9,  500] loss:0.078\n",
      "[9,  600] loss:0.078\n",
      "[9,  700] loss:0.079\n",
      "[10,  100] loss:0.077\n",
      "[10,  200] loss:0.077\n",
      "[10,  300] loss:0.078\n",
      "[10,  400] loss:0.078\n",
      "[10,  500] loss:0.077\n",
      "[10,  600] loss:0.077\n",
      "[10,  700] loss:0.078\n",
      "[11,  100] loss:0.076\n",
      "[11,  200] loss:0.076\n",
      "[11,  300] loss:0.077\n",
      "[11,  400] loss:0.076\n",
      "[11,  500] loss:0.077\n",
      "[11,  600] loss:0.077\n",
      "[11,  700] loss:0.078\n",
      "[12,  100] loss:0.077\n",
      "[12,  200] loss:0.076\n",
      "[12,  300] loss:0.076\n",
      "[12,  400] loss:0.076\n",
      "[12,  500] loss:0.077\n",
      "[12,  600] loss:0.077\n",
      "[12,  700] loss:0.077\n",
      "[13,  100] loss:0.077\n",
      "[13,  200] loss:0.076\n",
      "[13,  300] loss:0.075\n",
      "[13,  400] loss:0.077\n",
      "[13,  500] loss:0.076\n",
      "[13,  600] loss:0.076\n",
      "[13,  700] loss:0.076\n",
      "[14,  100] loss:0.075\n",
      "[14,  200] loss:0.076\n",
      "[14,  300] loss:0.077\n",
      "[14,  400] loss:0.075\n",
      "[14,  500] loss:0.075\n",
      "[14,  600] loss:0.075\n",
      "[14,  700] loss:0.076\n",
      "[15,  100] loss:0.075\n",
      "[15,  200] loss:0.075\n",
      "[15,  300] loss:0.075\n",
      "[15,  400] loss:0.076\n",
      "[15,  500] loss:0.076\n",
      "[15,  600] loss:0.075\n",
      "[15,  700] loss:0.075\n",
      "[16,  100] loss:0.075\n",
      "[16,  200] loss:0.075\n",
      "[16,  300] loss:0.075\n",
      "[16,  400] loss:0.074\n",
      "[16,  500] loss:0.075\n",
      "[16,  600] loss:0.075\n",
      "[16,  700] loss:0.075\n",
      "[17,  100] loss:0.076\n",
      "[17,  200] loss:0.075\n",
      "[17,  300] loss:0.075\n",
      "[17,  400] loss:0.074\n",
      "[17,  500] loss:0.075\n",
      "[17,  600] loss:0.074\n",
      "[17,  700] loss:0.074\n",
      "[18,  100] loss:0.075\n",
      "[18,  200] loss:0.075\n",
      "[18,  300] loss:0.075\n",
      "[18,  400] loss:0.074\n",
      "[18,  500] loss:0.075\n",
      "[18,  600] loss:0.074\n",
      "[18,  700] loss:0.074\n",
      "[19,  100] loss:0.075\n",
      "[19,  200] loss:0.075\n",
      "[19,  300] loss:0.074\n",
      "[19,  400] loss:0.074\n",
      "[19,  500] loss:0.074\n",
      "[19,  600] loss:0.073\n",
      "[19,  700] loss:0.075\n",
      "[20,  100] loss:0.073\n",
      "[20,  200] loss:0.074\n",
      "[20,  300] loss:0.074\n",
      "[20,  400] loss:0.074\n",
      "[20,  500] loss:0.074\n",
      "[20,  600] loss:0.075\n",
      "[20,  700] loss:0.074\n",
      "[21,  100] loss:0.074\n",
      "[21,  200] loss:0.074\n",
      "[21,  300] loss:0.074\n",
      "[21,  400] loss:0.073\n",
      "[21,  500] loss:0.074\n",
      "[21,  600] loss:0.073\n",
      "[21,  700] loss:0.074\n",
      "[22,  100] loss:0.071\n",
      "[22,  200] loss:0.074\n",
      "[22,  300] loss:0.074\n",
      "[22,  400] loss:0.073\n",
      "[22,  500] loss:0.073\n",
      "[22,  600] loss:0.074\n",
      "[22,  700] loss:0.074\n",
      "[23,  100] loss:0.072\n",
      "[23,  200] loss:0.073\n",
      "[23,  300] loss:0.073\n",
      "[23,  400] loss:0.073\n",
      "[23,  500] loss:0.073\n",
      "[23,  600] loss:0.074\n",
      "[23,  700] loss:0.073\n",
      "[24,  100] loss:0.072\n",
      "[24,  200] loss:0.073\n",
      "[24,  300] loss:0.073\n",
      "[24,  400] loss:0.073\n",
      "[24,  500] loss:0.073\n",
      "[24,  600] loss:0.073\n",
      "[24,  700] loss:0.073\n",
      "[25,  100] loss:0.073\n",
      "[25,  200] loss:0.073\n",
      "[25,  300] loss:0.073\n",
      "[25,  400] loss:0.073\n",
      "[25,  500] loss:0.073\n",
      "[25,  600] loss:0.073\n",
      "[25,  700] loss:0.073\n",
      "[26,  100] loss:0.073\n",
      "[26,  200] loss:0.072\n",
      "[26,  300] loss:0.074\n",
      "[26,  400] loss:0.073\n",
      "[26,  500] loss:0.072\n",
      "[26,  600] loss:0.072\n",
      "[26,  700] loss:0.073\n",
      "[27,  100] loss:0.073\n",
      "[27,  200] loss:0.073\n",
      "[27,  300] loss:0.072\n",
      "[27,  400] loss:0.072\n",
      "[27,  500] loss:0.072\n",
      "[27,  600] loss:0.072\n",
      "[27,  700] loss:0.073\n",
      "[28,  100] loss:0.072\n",
      "[28,  200] loss:0.072\n",
      "[28,  300] loss:0.072\n",
      "[28,  400] loss:0.072\n",
      "[28,  500] loss:0.073\n",
      "[28,  600] loss:0.072\n",
      "[28,  700] loss:0.072\n",
      "[29,  100] loss:0.072\n",
      "[29,  200] loss:0.072\n",
      "[29,  300] loss:0.072\n",
      "[29,  400] loss:0.072\n",
      "[29,  500] loss:0.071\n",
      "[29,  600] loss:0.071\n",
      "[29,  700] loss:0.073\n",
      "[30,  100] loss:0.071\n",
      "[30,  200] loss:0.072\n",
      "[30,  300] loss:0.072\n",
      "[30,  400] loss:0.072\n",
      "[30,  500] loss:0.071\n",
      "[30,  600] loss:0.072\n",
      "[30,  700] loss:0.072\n",
      "[31,  100] loss:0.071\n",
      "[31,  200] loss:0.073\n",
      "[31,  300] loss:0.072\n",
      "[31,  400] loss:0.072\n",
      "[31,  500] loss:0.072\n",
      "[31,  600] loss:0.072\n",
      "[31,  700] loss:0.072\n",
      "[32,  100] loss:0.072\n",
      "[32,  200] loss:0.072\n",
      "[32,  300] loss:0.072\n",
      "[32,  400] loss:0.071\n",
      "[32,  500] loss:0.072\n",
      "[32,  600] loss:0.071\n",
      "[32,  700] loss:0.071\n",
      "[33,  100] loss:0.071\n",
      "[33,  200] loss:0.070\n",
      "[33,  300] loss:0.071\n",
      "[33,  400] loss:0.072\n",
      "[33,  500] loss:0.072\n",
      "[33,  600] loss:0.071\n",
      "[33,  700] loss:0.072\n",
      "[34,  100] loss:0.070\n",
      "[34,  200] loss:0.072\n",
      "[34,  300] loss:0.071\n",
      "[34,  400] loss:0.070\n",
      "[34,  500] loss:0.072\n",
      "[34,  600] loss:0.072\n",
      "[34,  700] loss:0.072\n",
      "[35,  100] loss:0.071\n",
      "[35,  200] loss:0.071\n",
      "[35,  300] loss:0.071\n",
      "[35,  400] loss:0.071\n",
      "[35,  500] loss:0.071\n",
      "[35,  600] loss:0.071\n",
      "[35,  700] loss:0.071\n",
      "[36,  100] loss:0.071\n",
      "[36,  200] loss:0.071\n",
      "[36,  300] loss:0.071\n",
      "[36,  400] loss:0.071\n",
      "[36,  500] loss:0.071\n",
      "[36,  600] loss:0.071\n",
      "[36,  700] loss:0.071\n",
      "[37,  100] loss:0.071\n",
      "[37,  200] loss:0.070\n",
      "[37,  300] loss:0.071\n",
      "[37,  400] loss:0.071\n",
      "[37,  500] loss:0.072\n",
      "[37,  600] loss:0.072\n",
      "[37,  700] loss:0.070\n",
      "[38,  100] loss:0.070\n",
      "[38,  200] loss:0.071\n",
      "[38,  300] loss:0.071\n",
      "[38,  400] loss:0.071\n",
      "[38,  500] loss:0.071\n",
      "[38,  600] loss:0.071\n",
      "[38,  700] loss:0.071\n",
      "[39,  100] loss:0.071\n",
      "[39,  200] loss:0.071\n",
      "[39,  300] loss:0.070\n",
      "[39,  400] loss:0.071\n",
      "[39,  500] loss:0.070\n",
      "[39,  600] loss:0.071\n",
      "[39,  700] loss:0.070\n",
      "[40,  100] loss:0.071\n",
      "[40,  200] loss:0.070\n",
      "[40,  300] loss:0.070\n",
      "[40,  400] loss:0.070\n",
      "[40,  500] loss:0.070\n",
      "[40,  600] loss:0.070\n",
      "[40,  700] loss:0.071\n",
      "[41,  100] loss:0.070\n",
      "[41,  200] loss:0.070\n",
      "[41,  300] loss:0.070\n",
      "[41,  400] loss:0.070\n",
      "[41,  500] loss:0.070\n",
      "[41,  600] loss:0.071\n",
      "[41,  700] loss:0.071\n",
      "[42,  100] loss:0.070\n",
      "[42,  200] loss:0.070\n",
      "[42,  300] loss:0.070\n",
      "[42,  400] loss:0.069\n",
      "[42,  500] loss:0.070\n",
      "[42,  600] loss:0.070\n",
      "[42,  700] loss:0.070\n",
      "[43,  100] loss:0.070\n",
      "[43,  200] loss:0.069\n",
      "[43,  300] loss:0.070\n",
      "[43,  400] loss:0.071\n",
      "[43,  500] loss:0.070\n",
      "[43,  600] loss:0.070\n",
      "[43,  700] loss:0.071\n",
      "[44,  100] loss:0.070\n",
      "[44,  200] loss:0.070\n",
      "[44,  300] loss:0.070\n",
      "[44,  400] loss:0.070\n",
      "[44,  500] loss:0.070\n",
      "[44,  600] loss:0.070\n",
      "[44,  700] loss:0.069\n",
      "[45,  100] loss:0.069\n",
      "[45,  200] loss:0.070\n",
      "[45,  300] loss:0.069\n",
      "[45,  400] loss:0.071\n",
      "[45,  500] loss:0.070\n",
      "[45,  600] loss:0.070\n",
      "[45,  700] loss:0.070\n",
      "[46,  100] loss:0.070\n",
      "[46,  200] loss:0.069\n",
      "[46,  300] loss:0.070\n",
      "[46,  400] loss:0.070\n",
      "[46,  500] loss:0.070\n",
      "[46,  600] loss:0.070\n",
      "[46,  700] loss:0.070\n",
      "[47,  100] loss:0.069\n",
      "[47,  200] loss:0.069\n",
      "[47,  300] loss:0.069\n",
      "[47,  400] loss:0.070\n",
      "[47,  500] loss:0.070\n",
      "[47,  600] loss:0.069\n",
      "[47,  700] loss:0.070\n",
      "[48,  100] loss:0.069\n",
      "[48,  200] loss:0.069\n",
      "[48,  300] loss:0.069\n",
      "[48,  400] loss:0.070\n",
      "[48,  500] loss:0.069\n",
      "[48,  600] loss:0.070\n",
      "[48,  700] loss:0.069\n",
      "[49,  100] loss:0.069\n",
      "[49,  200] loss:0.070\n",
      "[49,  300] loss:0.070\n",
      "[49,  400] loss:0.070\n",
      "[49,  500] loss:0.069\n",
      "[49,  600] loss:0.068\n",
      "[49,  700] loss:0.070\n",
      "[50,  100] loss:0.069\n",
      "[50,  200] loss:0.070\n",
      "[50,  300] loss:0.070\n",
      "[50,  400] loss:0.069\n",
      "[50,  500] loss:0.069\n",
      "[50,  600] loss:0.070\n",
      "[50,  700] loss:0.069\n",
      "[51,  100] loss:0.070\n",
      "[51,  200] loss:0.068\n",
      "[51,  300] loss:0.069\n",
      "[51,  400] loss:0.069\n",
      "[51,  500] loss:0.069\n",
      "[51,  600] loss:0.070\n",
      "[51,  700] loss:0.069\n",
      "[52,  100] loss:0.070\n",
      "[52,  200] loss:0.069\n",
      "[52,  300] loss:0.069\n",
      "[52,  400] loss:0.069\n",
      "[52,  500] loss:0.069\n",
      "[52,  600] loss:0.069\n",
      "[52,  700] loss:0.069\n",
      "[53,  100] loss:0.069\n",
      "[53,  200] loss:0.068\n",
      "[53,  300] loss:0.070\n",
      "[53,  400] loss:0.068\n",
      "[53,  500] loss:0.069\n",
      "[53,  600] loss:0.069\n",
      "[53,  700] loss:0.070\n",
      "[54,  100] loss:0.070\n",
      "[54,  200] loss:0.068\n",
      "[54,  300] loss:0.068\n",
      "[54,  400] loss:0.069\n",
      "[54,  500] loss:0.068\n",
      "[54,  600] loss:0.069\n",
      "[54,  700] loss:0.069\n",
      "[55,  100] loss:0.069\n",
      "[55,  200] loss:0.069\n",
      "[55,  300] loss:0.069\n",
      "[55,  400] loss:0.068\n",
      "[55,  500] loss:0.069\n",
      "[55,  600] loss:0.068\n",
      "[55,  700] loss:0.069\n",
      "[56,  100] loss:0.070\n",
      "[56,  200] loss:0.068\n",
      "[56,  300] loss:0.068\n",
      "[56,  400] loss:0.069\n",
      "[56,  500] loss:0.070\n",
      "[56,  600] loss:0.068\n",
      "[56,  700] loss:0.069\n",
      "[57,  100] loss:0.068\n",
      "[57,  200] loss:0.068\n",
      "[57,  300] loss:0.068\n",
      "[57,  400] loss:0.069\n",
      "[57,  500] loss:0.069\n",
      "[57,  600] loss:0.068\n",
      "[57,  700] loss:0.069\n",
      "[58,  100] loss:0.069\n",
      "[58,  200] loss:0.069\n",
      "[58,  300] loss:0.069\n",
      "[58,  400] loss:0.068\n",
      "[58,  500] loss:0.069\n",
      "[58,  600] loss:0.068\n",
      "[58,  700] loss:0.069\n",
      "[59,  100] loss:0.068\n",
      "[59,  200] loss:0.069\n",
      "[59,  300] loss:0.069\n",
      "[59,  400] loss:0.069\n",
      "[59,  500] loss:0.068\n",
      "[59,  600] loss:0.068\n",
      "[59,  700] loss:0.068\n",
      "[60,  100] loss:0.068\n",
      "[60,  200] loss:0.069\n",
      "[60,  300] loss:0.068\n",
      "[60,  400] loss:0.068\n",
      "[60,  500] loss:0.068\n",
      "[60,  600] loss:0.068\n",
      "[60,  700] loss:0.069\n",
      "[61,  100] loss:0.068\n",
      "[61,  200] loss:0.068\n",
      "[61,  300] loss:0.068\n",
      "[61,  400] loss:0.069\n",
      "[61,  500] loss:0.068\n",
      "[61,  600] loss:0.068\n",
      "[61,  700] loss:0.068\n",
      "[62,  100] loss:0.069\n",
      "[62,  200] loss:0.068\n",
      "[62,  300] loss:0.068\n",
      "[62,  400] loss:0.068\n",
      "[62,  500] loss:0.069\n",
      "[62,  600] loss:0.069\n",
      "[62,  700] loss:0.068\n",
      "[63,  100] loss:0.068\n",
      "[63,  200] loss:0.067\n",
      "[63,  300] loss:0.068\n",
      "[63,  400] loss:0.068\n",
      "[63,  500] loss:0.069\n",
      "[63,  600] loss:0.067\n",
      "[63,  700] loss:0.068\n",
      "[64,  100] loss:0.068\n",
      "[64,  200] loss:0.068\n",
      "[64,  300] loss:0.068\n",
      "[64,  400] loss:0.067\n",
      "[64,  500] loss:0.068\n",
      "[64,  600] loss:0.068\n",
      "[64,  700] loss:0.067\n",
      "[65,  100] loss:0.068\n",
      "[65,  200] loss:0.069\n",
      "[65,  300] loss:0.068\n",
      "[65,  400] loss:0.068\n",
      "[65,  500] loss:0.069\n",
      "[65,  600] loss:0.068\n",
      "[65,  700] loss:0.068\n",
      "[66,  100] loss:0.068\n",
      "[66,  200] loss:0.068\n",
      "[66,  300] loss:0.068\n",
      "[66,  400] loss:0.069\n",
      "[66,  500] loss:0.068\n",
      "[66,  600] loss:0.068\n",
      "[66,  700] loss:0.069\n",
      "[67,  100] loss:0.068\n",
      "[67,  200] loss:0.068\n",
      "[67,  300] loss:0.067\n",
      "[67,  400] loss:0.069\n",
      "[67,  500] loss:0.068\n",
      "[67,  600] loss:0.068\n",
      "[67,  700] loss:0.069\n",
      "[68,  100] loss:0.067\n",
      "[68,  200] loss:0.068\n",
      "[68,  300] loss:0.068\n",
      "[68,  400] loss:0.067\n",
      "[68,  500] loss:0.068\n",
      "[68,  600] loss:0.067\n",
      "[68,  700] loss:0.068\n",
      "[69,  100] loss:0.067\n",
      "[69,  200] loss:0.067\n",
      "[69,  300] loss:0.068\n",
      "[69,  400] loss:0.068\n",
      "[69,  500] loss:0.068\n",
      "[69,  600] loss:0.067\n",
      "[69,  700] loss:0.068\n",
      "[70,  100] loss:0.068\n",
      "[70,  200] loss:0.068\n",
      "[70,  300] loss:0.068\n",
      "[70,  400] loss:0.068\n",
      "[70,  500] loss:0.068\n",
      "[70,  600] loss:0.068\n",
      "[70,  700] loss:0.067\n",
      "[71,  100] loss:0.067\n",
      "[71,  200] loss:0.067\n",
      "[71,  300] loss:0.068\n",
      "[71,  400] loss:0.067\n",
      "[71,  500] loss:0.067\n",
      "[71,  600] loss:0.067\n",
      "[71,  700] loss:0.068\n",
      "[72,  100] loss:0.067\n",
      "[72,  200] loss:0.068\n",
      "[72,  300] loss:0.067\n",
      "[72,  400] loss:0.068\n",
      "[72,  500] loss:0.068\n",
      "[72,  600] loss:0.067\n",
      "[72,  700] loss:0.067\n",
      "[73,  100] loss:0.067\n",
      "[73,  200] loss:0.067\n",
      "[73,  300] loss:0.067\n",
      "[73,  400] loss:0.067\n",
      "[73,  500] loss:0.067\n",
      "[73,  600] loss:0.067\n",
      "[73,  700] loss:0.068\n",
      "[74,  100] loss:0.068\n",
      "[74,  200] loss:0.067\n",
      "[74,  300] loss:0.067\n",
      "[74,  400] loss:0.067\n",
      "[74,  500] loss:0.068\n",
      "[74,  600] loss:0.067\n",
      "[74,  700] loss:0.067\n",
      "[75,  100] loss:0.067\n",
      "[75,  200] loss:0.067\n",
      "[75,  300] loss:0.067\n",
      "[75,  400] loss:0.068\n",
      "[75,  500] loss:0.067\n",
      "[75,  600] loss:0.068\n",
      "[75,  700] loss:0.068\n",
      "[76,  100] loss:0.068\n",
      "[76,  200] loss:0.067\n",
      "[76,  300] loss:0.067\n",
      "[76,  400] loss:0.067\n",
      "[76,  500] loss:0.067\n",
      "[76,  600] loss:0.067\n",
      "[76,  700] loss:0.066\n",
      "[77,  100] loss:0.067\n",
      "[77,  200] loss:0.067\n",
      "[77,  300] loss:0.067\n",
      "[77,  400] loss:0.067\n",
      "[77,  500] loss:0.067\n",
      "[77,  600] loss:0.068\n",
      "[77,  700] loss:0.068\n",
      "[78,  100] loss:0.067\n",
      "[78,  200] loss:0.068\n",
      "[78,  300] loss:0.067\n",
      "[78,  400] loss:0.068\n",
      "[78,  500] loss:0.066\n",
      "[78,  600] loss:0.068\n",
      "[78,  700] loss:0.066\n",
      "[79,  100] loss:0.066\n",
      "[79,  200] loss:0.067\n",
      "[79,  300] loss:0.067\n",
      "[79,  400] loss:0.067\n",
      "[79,  500] loss:0.067\n",
      "[79,  600] loss:0.067\n",
      "[79,  700] loss:0.067\n",
      "[80,  100] loss:0.067\n",
      "[80,  200] loss:0.067\n",
      "[80,  300] loss:0.067\n",
      "[80,  400] loss:0.067\n",
      "[80,  500] loss:0.067\n",
      "[80,  600] loss:0.067\n",
      "[80,  700] loss:0.068\n",
      "[81,  100] loss:0.067\n",
      "[81,  200] loss:0.067\n",
      "[81,  300] loss:0.067\n",
      "[81,  400] loss:0.068\n",
      "[81,  500] loss:0.067\n",
      "[81,  600] loss:0.067\n",
      "[81,  700] loss:0.067\n",
      "[82,  100] loss:0.066\n",
      "[82,  200] loss:0.067\n",
      "[82,  300] loss:0.066\n",
      "[82,  400] loss:0.067\n",
      "[82,  500] loss:0.067\n",
      "[82,  600] loss:0.066\n",
      "[82,  700] loss:0.067\n",
      "[83,  100] loss:0.068\n",
      "[83,  200] loss:0.066\n",
      "[83,  300] loss:0.066\n",
      "[83,  400] loss:0.068\n",
      "[83,  500] loss:0.067\n",
      "[83,  600] loss:0.066\n",
      "[83,  700] loss:0.067\n",
      "[84,  100] loss:0.067\n",
      "[84,  200] loss:0.066\n",
      "[84,  300] loss:0.067\n",
      "[84,  400] loss:0.067\n",
      "[84,  500] loss:0.067\n",
      "[84,  600] loss:0.067\n",
      "[84,  700] loss:0.066\n",
      "[85,  100] loss:0.067\n",
      "[85,  200] loss:0.066\n",
      "[85,  300] loss:0.067\n",
      "[85,  400] loss:0.067\n",
      "[85,  500] loss:0.066\n",
      "[85,  600] loss:0.067\n",
      "[85,  700] loss:0.067\n",
      "[86,  100] loss:0.067\n",
      "[86,  200] loss:0.067\n",
      "[86,  300] loss:0.067\n",
      "[86,  400] loss:0.067\n",
      "[86,  500] loss:0.066\n",
      "[86,  600] loss:0.067\n",
      "[86,  700] loss:0.067\n",
      "[87,  100] loss:0.066\n",
      "[87,  200] loss:0.066\n",
      "[87,  300] loss:0.067\n",
      "[87,  400] loss:0.067\n",
      "[87,  500] loss:0.066\n",
      "[87,  600] loss:0.066\n",
      "[87,  700] loss:0.067\n",
      "[88,  100] loss:0.066\n",
      "[88,  200] loss:0.067\n",
      "[88,  300] loss:0.067\n",
      "[88,  400] loss:0.066\n",
      "[88,  500] loss:0.066\n",
      "[88,  600] loss:0.067\n",
      "[88,  700] loss:0.067\n",
      "[89,  100] loss:0.066\n",
      "[89,  200] loss:0.067\n",
      "[89,  300] loss:0.066\n",
      "[89,  400] loss:0.067\n",
      "[89,  500] loss:0.066\n",
      "[89,  600] loss:0.067\n",
      "[89,  700] loss:0.067\n",
      "[90,  100] loss:0.067\n",
      "[90,  200] loss:0.066\n",
      "[90,  300] loss:0.067\n",
      "[90,  400] loss:0.066\n",
      "[90,  500] loss:0.066\n",
      "[90,  600] loss:0.067\n",
      "[90,  700] loss:0.066\n",
      "[91,  100] loss:0.066\n",
      "[91,  200] loss:0.067\n",
      "[91,  300] loss:0.066\n",
      "[91,  400] loss:0.067\n",
      "[91,  500] loss:0.066\n",
      "[91,  600] loss:0.067\n",
      "[91,  700] loss:0.066\n",
      "[92,  100] loss:0.066\n",
      "[92,  200] loss:0.067\n",
      "[92,  300] loss:0.066\n",
      "[92,  400] loss:0.066\n",
      "[92,  500] loss:0.067\n",
      "[92,  600] loss:0.067\n",
      "[92,  700] loss:0.067\n",
      "[93,  100] loss:0.066\n",
      "[93,  200] loss:0.067\n",
      "[93,  300] loss:0.066\n",
      "[93,  400] loss:0.067\n",
      "[93,  500] loss:0.066\n",
      "[93,  600] loss:0.066\n",
      "[93,  700] loss:0.066\n",
      "[94,  100] loss:0.067\n",
      "[94,  200] loss:0.066\n",
      "[94,  300] loss:0.067\n",
      "[94,  400] loss:0.066\n",
      "[94,  500] loss:0.066\n",
      "[94,  600] loss:0.065\n",
      "[94,  700] loss:0.066\n",
      "[95,  100] loss:0.066\n",
      "[95,  200] loss:0.066\n",
      "[95,  300] loss:0.066\n",
      "[95,  400] loss:0.066\n",
      "[95,  500] loss:0.067\n",
      "[95,  600] loss:0.066\n",
      "[95,  700] loss:0.067\n",
      "[96,  100] loss:0.066\n",
      "[96,  200] loss:0.066\n",
      "[96,  300] loss:0.067\n",
      "[96,  400] loss:0.066\n",
      "[96,  500] loss:0.066\n",
      "[96,  600] loss:0.067\n",
      "[96,  700] loss:0.066\n",
      "[97,  100] loss:0.066\n",
      "[97,  200] loss:0.066\n",
      "[97,  300] loss:0.065\n",
      "[97,  400] loss:0.066\n",
      "[97,  500] loss:0.066\n",
      "[97,  600] loss:0.066\n",
      "[97,  700] loss:0.066\n",
      "[98,  100] loss:0.065\n",
      "[98,  200] loss:0.067\n",
      "[98,  300] loss:0.066\n",
      "[98,  400] loss:0.066\n",
      "[98,  500] loss:0.066\n",
      "[98,  600] loss:0.066\n",
      "[98,  700] loss:0.066\n",
      "[99,  100] loss:0.066\n",
      "[99,  200] loss:0.066\n",
      "[99,  300] loss:0.066\n",
      "[99,  400] loss:0.065\n",
      "[99,  500] loss:0.066\n",
      "[99,  600] loss:0.066\n",
      "[99,  700] loss:0.066\n",
      "[100,  100] loss:0.066\n",
      "[100,  200] loss:0.066\n",
      "[100,  300] loss:0.066\n",
      "[100,  400] loss:0.066\n",
      "[100,  500] loss:0.065\n",
      "[100,  600] loss:0.065\n",
      "[100,  700] loss:0.066\n",
      "[101,  100] loss:0.066\n",
      "[101,  200] loss:0.065\n",
      "[101,  300] loss:0.066\n",
      "[101,  400] loss:0.067\n",
      "[101,  500] loss:0.066\n",
      "[101,  600] loss:0.065\n",
      "[101,  700] loss:0.066\n",
      "[102,  100] loss:0.066\n",
      "[102,  200] loss:0.066\n",
      "[102,  300] loss:0.066\n",
      "[102,  400] loss:0.065\n",
      "[102,  500] loss:0.066\n",
      "[102,  600] loss:0.066\n",
      "[102,  700] loss:0.066\n",
      "[103,  100] loss:0.066\n",
      "[103,  200] loss:0.066\n",
      "[103,  300] loss:0.066\n",
      "[103,  400] loss:0.066\n",
      "[103,  500] loss:0.066\n",
      "[103,  600] loss:0.066\n",
      "[103,  700] loss:0.066\n",
      "[104,  100] loss:0.066\n",
      "[104,  200] loss:0.065\n",
      "[104,  300] loss:0.066\n",
      "[104,  400] loss:0.066\n",
      "[104,  500] loss:0.066\n",
      "[104,  600] loss:0.066\n",
      "[104,  700] loss:0.066\n",
      "[105,  100] loss:0.066\n",
      "[105,  200] loss:0.065\n",
      "[105,  300] loss:0.065\n",
      "[105,  400] loss:0.066\n",
      "[105,  500] loss:0.066\n",
      "[105,  600] loss:0.066\n",
      "[105,  700] loss:0.066\n",
      "[106,  100] loss:0.066\n",
      "[106,  200] loss:0.066\n",
      "[106,  300] loss:0.066\n",
      "[106,  400] loss:0.066\n",
      "[106,  500] loss:0.066\n",
      "[106,  600] loss:0.065\n",
      "[106,  700] loss:0.066\n",
      "[107,  100] loss:0.066\n",
      "[107,  200] loss:0.065\n",
      "[107,  300] loss:0.065\n",
      "[107,  400] loss:0.066\n",
      "[107,  500] loss:0.066\n",
      "[107,  600] loss:0.065\n",
      "[107,  700] loss:0.066\n",
      "[108,  100] loss:0.066\n",
      "[108,  200] loss:0.066\n",
      "[108,  300] loss:0.066\n",
      "[108,  400] loss:0.066\n",
      "[108,  500] loss:0.066\n",
      "[108,  600] loss:0.065\n",
      "[108,  700] loss:0.065\n",
      "[109,  100] loss:0.065\n",
      "[109,  200] loss:0.066\n",
      "[109,  300] loss:0.065\n",
      "[109,  400] loss:0.066\n",
      "[109,  500] loss:0.065\n",
      "[109,  600] loss:0.065\n",
      "[109,  700] loss:0.066\n",
      "[110,  100] loss:0.066\n",
      "[110,  200] loss:0.066\n",
      "[110,  300] loss:0.066\n",
      "[110,  400] loss:0.065\n",
      "[110,  500] loss:0.065\n",
      "[110,  600] loss:0.065\n",
      "[110,  700] loss:0.066\n",
      "[111,  100] loss:0.066\n",
      "[111,  200] loss:0.065\n",
      "[111,  300] loss:0.065\n",
      "[111,  400] loss:0.066\n",
      "[111,  500] loss:0.066\n",
      "[111,  600] loss:0.066\n",
      "[111,  700] loss:0.064\n",
      "[112,  100] loss:0.066\n",
      "[112,  200] loss:0.065\n",
      "[112,  300] loss:0.066\n",
      "[112,  400] loss:0.065\n",
      "[112,  500] loss:0.066\n",
      "[112,  600] loss:0.065\n",
      "[112,  700] loss:0.066\n",
      "[113,  100] loss:0.066\n",
      "[113,  200] loss:0.066\n",
      "[113,  300] loss:0.065\n",
      "[113,  400] loss:0.065\n",
      "[113,  500] loss:0.065\n",
      "[113,  600] loss:0.065\n",
      "[113,  700] loss:0.065\n",
      "[114,  100] loss:0.065\n",
      "[114,  200] loss:0.065\n",
      "[114,  300] loss:0.065\n",
      "[114,  400] loss:0.065\n",
      "[114,  500] loss:0.065\n",
      "[114,  600] loss:0.065\n",
      "[114,  700] loss:0.066\n",
      "[115,  100] loss:0.065\n",
      "[115,  200] loss:0.065\n",
      "[115,  300] loss:0.064\n",
      "[115,  400] loss:0.065\n",
      "[115,  500] loss:0.065\n",
      "[115,  600] loss:0.066\n",
      "[115,  700] loss:0.066\n",
      "[116,  100] loss:0.065\n",
      "[116,  200] loss:0.065\n",
      "[116,  300] loss:0.066\n",
      "[116,  400] loss:0.065\n",
      "[116,  500] loss:0.065\n",
      "[116,  600] loss:0.065\n",
      "[116,  700] loss:0.065\n",
      "[117,  100] loss:0.065\n",
      "[117,  200] loss:0.065\n",
      "[117,  300] loss:0.066\n",
      "[117,  400] loss:0.065\n",
      "[117,  500] loss:0.065\n",
      "[117,  600] loss:0.065\n",
      "[117,  700] loss:0.065\n",
      "[118,  100] loss:0.064\n",
      "[118,  200] loss:0.065\n",
      "[118,  300] loss:0.065\n",
      "[118,  400] loss:0.065\n",
      "[118,  500] loss:0.065\n",
      "[118,  600] loss:0.065\n",
      "[118,  700] loss:0.065\n",
      "[119,  100] loss:0.065\n",
      "[119,  200] loss:0.065\n",
      "[119,  300] loss:0.065\n",
      "[119,  400] loss:0.065\n",
      "[119,  500] loss:0.065\n",
      "[119,  600] loss:0.065\n",
      "[119,  700] loss:0.065\n",
      "[120,  100] loss:0.065\n",
      "[120,  200] loss:0.065\n",
      "[120,  300] loss:0.065\n",
      "[120,  400] loss:0.065\n",
      "[120,  500] loss:0.065\n",
      "[120,  600] loss:0.065\n",
      "[120,  700] loss:0.065\n",
      "[121,  100] loss:0.065\n",
      "[121,  200] loss:0.065\n",
      "[121,  300] loss:0.064\n",
      "[121,  400] loss:0.066\n",
      "[121,  500] loss:0.065\n",
      "[121,  600] loss:0.065\n",
      "[121,  700] loss:0.065\n",
      "[122,  100] loss:0.065\n",
      "[122,  200] loss:0.065\n",
      "[122,  300] loss:0.065\n",
      "[122,  400] loss:0.065\n",
      "[122,  500] loss:0.065\n",
      "[122,  600] loss:0.065\n",
      "[122,  700] loss:0.065\n",
      "[123,  100] loss:0.065\n",
      "[123,  200] loss:0.065\n",
      "[123,  300] loss:0.065\n",
      "[123,  400] loss:0.064\n",
      "[123,  500] loss:0.066\n",
      "[123,  600] loss:0.066\n",
      "[123,  700] loss:0.065\n",
      "[124,  100] loss:0.065\n",
      "[124,  200] loss:0.065\n",
      "[124,  300] loss:0.065\n",
      "[124,  400] loss:0.065\n",
      "[124,  500] loss:0.065\n",
      "[124,  600] loss:0.064\n",
      "[124,  700] loss:0.065\n",
      "[125,  100] loss:0.065\n",
      "[125,  200] loss:0.064\n",
      "[125,  300] loss:0.064\n",
      "[125,  400] loss:0.066\n",
      "[125,  500] loss:0.065\n",
      "[125,  600] loss:0.064\n",
      "[125,  700] loss:0.064\n",
      "[126,  100] loss:0.065\n",
      "[126,  200] loss:0.065\n",
      "[126,  300] loss:0.065\n",
      "[126,  400] loss:0.064\n",
      "[126,  500] loss:0.065\n",
      "[126,  600] loss:0.065\n",
      "[126,  700] loss:0.065\n",
      "[127,  100] loss:0.065\n",
      "[127,  200] loss:0.065\n",
      "[127,  300] loss:0.064\n",
      "[127,  400] loss:0.064\n",
      "[127,  500] loss:0.064\n",
      "[127,  600] loss:0.065\n",
      "[127,  700] loss:0.066\n",
      "[128,  100] loss:0.065\n",
      "[128,  200] loss:0.065\n",
      "[128,  300] loss:0.064\n",
      "[128,  400] loss:0.065\n",
      "[128,  500] loss:0.066\n",
      "[128,  600] loss:0.065\n",
      "[128,  700] loss:0.065\n",
      "[129,  100] loss:0.065\n",
      "[129,  200] loss:0.064\n",
      "[129,  300] loss:0.064\n",
      "[129,  400] loss:0.064\n",
      "[129,  500] loss:0.066\n",
      "[129,  600] loss:0.065\n",
      "[129,  700] loss:0.065\n",
      "[130,  100] loss:0.065\n",
      "[130,  200] loss:0.064\n",
      "[130,  300] loss:0.064\n",
      "[130,  400] loss:0.065\n",
      "[130,  500] loss:0.065\n",
      "[130,  600] loss:0.065\n",
      "[130,  700] loss:0.065\n",
      "[131,  100] loss:0.064\n",
      "[131,  200] loss:0.065\n",
      "[131,  300] loss:0.065\n",
      "[131,  400] loss:0.064\n",
      "[131,  500] loss:0.064\n",
      "[131,  600] loss:0.065\n",
      "[131,  700] loss:0.065\n",
      "[132,  100] loss:0.065\n",
      "[132,  200] loss:0.063\n",
      "[132,  300] loss:0.064\n",
      "[132,  400] loss:0.065\n",
      "[132,  500] loss:0.064\n",
      "[132,  600] loss:0.065\n",
      "[132,  700] loss:0.065\n",
      "[133,  100] loss:0.065\n",
      "[133,  200] loss:0.065\n",
      "[133,  300] loss:0.065\n",
      "[133,  400] loss:0.064\n",
      "[133,  500] loss:0.065\n",
      "[133,  600] loss:0.064\n",
      "[133,  700] loss:0.065\n",
      "[134,  100] loss:0.065\n",
      "[134,  200] loss:0.064\n",
      "[134,  300] loss:0.064\n",
      "[134,  400] loss:0.064\n",
      "[134,  500] loss:0.065\n",
      "[134,  600] loss:0.065\n",
      "[134,  700] loss:0.065\n",
      "[135,  100] loss:0.064\n",
      "[135,  200] loss:0.066\n",
      "[135,  300] loss:0.065\n",
      "[135,  400] loss:0.064\n",
      "[135,  500] loss:0.065\n",
      "[135,  600] loss:0.065\n",
      "[135,  700] loss:0.065\n",
      "[136,  100] loss:0.065\n",
      "[136,  200] loss:0.063\n",
      "[136,  300] loss:0.065\n",
      "[136,  400] loss:0.064\n",
      "[136,  500] loss:0.065\n",
      "[136,  600] loss:0.064\n",
      "[136,  700] loss:0.066\n",
      "[137,  100] loss:0.064\n",
      "[137,  200] loss:0.064\n",
      "[137,  300] loss:0.064\n",
      "[137,  400] loss:0.064\n",
      "[137,  500] loss:0.064\n",
      "[137,  600] loss:0.064\n",
      "[137,  700] loss:0.065\n",
      "[138,  100] loss:0.065\n",
      "[138,  200] loss:0.064\n",
      "[138,  300] loss:0.065\n",
      "[138,  400] loss:0.064\n",
      "[138,  500] loss:0.063\n",
      "[138,  600] loss:0.064\n",
      "[138,  700] loss:0.065\n",
      "[139,  100] loss:0.064\n",
      "[139,  200] loss:0.064\n",
      "[139,  300] loss:0.065\n",
      "[139,  400] loss:0.064\n",
      "[139,  500] loss:0.064\n",
      "[139,  600] loss:0.064\n",
      "[139,  700] loss:0.064\n",
      "[140,  100] loss:0.064\n",
      "[140,  200] loss:0.065\n",
      "[140,  300] loss:0.064\n",
      "[140,  400] loss:0.064\n",
      "[140,  500] loss:0.064\n",
      "[140,  600] loss:0.064\n",
      "[140,  700] loss:0.064\n",
      "[141,  100] loss:0.064\n",
      "[141,  200] loss:0.064\n",
      "[141,  300] loss:0.065\n",
      "[141,  400] loss:0.064\n",
      "[141,  500] loss:0.065\n",
      "[141,  600] loss:0.063\n",
      "[141,  700] loss:0.064\n",
      "[142,  100] loss:0.065\n",
      "[142,  200] loss:0.064\n",
      "[142,  300] loss:0.064\n",
      "[142,  400] loss:0.065\n",
      "[142,  500] loss:0.065\n",
      "[142,  600] loss:0.065\n",
      "[142,  700] loss:0.064\n",
      "[143,  100] loss:0.064\n",
      "[143,  200] loss:0.065\n",
      "[143,  300] loss:0.064\n",
      "[143,  400] loss:0.065\n",
      "[143,  500] loss:0.063\n",
      "[143,  600] loss:0.064\n",
      "[143,  700] loss:0.065\n",
      "[144,  100] loss:0.064\n",
      "[144,  200] loss:0.064\n",
      "[144,  300] loss:0.064\n",
      "[144,  400] loss:0.064\n",
      "[144,  500] loss:0.064\n",
      "[144,  600] loss:0.064\n",
      "[144,  700] loss:0.064\n",
      "[145,  100] loss:0.064\n",
      "[145,  200] loss:0.065\n",
      "[145,  300] loss:0.064\n",
      "[145,  400] loss:0.064\n",
      "[145,  500] loss:0.064\n",
      "[145,  600] loss:0.063\n",
      "[145,  700] loss:0.065\n",
      "[146,  100] loss:0.064\n",
      "[146,  200] loss:0.065\n",
      "[146,  300] loss:0.064\n",
      "[146,  400] loss:0.064\n",
      "[146,  500] loss:0.064\n",
      "[146,  600] loss:0.065\n",
      "[146,  700] loss:0.064\n",
      "[147,  100] loss:0.064\n",
      "[147,  200] loss:0.063\n",
      "[147,  300] loss:0.064\n",
      "[147,  400] loss:0.064\n",
      "[147,  500] loss:0.064\n",
      "[147,  600] loss:0.064\n",
      "[147,  700] loss:0.064\n",
      "[148,  100] loss:0.064\n",
      "[148,  200] loss:0.063\n",
      "[148,  300] loss:0.064\n",
      "[148,  400] loss:0.064\n",
      "[148,  500] loss:0.064\n",
      "[148,  600] loss:0.065\n",
      "[148,  700] loss:0.064\n",
      "[149,  100] loss:0.063\n",
      "[149,  200] loss:0.065\n",
      "[149,  300] loss:0.064\n",
      "[149,  400] loss:0.064\n",
      "[149,  500] loss:0.064\n",
      "[149,  600] loss:0.065\n",
      "[149,  700] loss:0.064\n",
      "[150,  100] loss:0.064\n",
      "[150,  200] loss:0.064\n",
      "[150,  300] loss:0.064\n",
      "[150,  400] loss:0.064\n",
      "[150,  500] loss:0.064\n",
      "[150,  600] loss:0.064\n",
      "[150,  700] loss:0.064\n",
      "[151,  100] loss:0.065\n",
      "[151,  200] loss:0.065\n",
      "[151,  300] loss:0.064\n",
      "[151,  400] loss:0.064\n",
      "[151,  500] loss:0.064\n",
      "[151,  600] loss:0.064\n",
      "[151,  700] loss:0.064\n",
      "[152,  100] loss:0.064\n",
      "[152,  200] loss:0.064\n",
      "[152,  300] loss:0.064\n",
      "[152,  400] loss:0.064\n",
      "[152,  500] loss:0.063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MR0A87~1.SHA\\AppData\\Local\\Temp/ipykernel_21508/3692931880.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mimg_rec_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mimg_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rec_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# img_rec = img_rec.view(-1, inputs.size(1), inputs.size(2), inputs.size(3))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# fake_labels = model(img_rec)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Notebook\\pytorch_program\\DefenseGAN-Pytorch-master\\DefenseGAN-Pytorch-master\\gan_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mDIM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(torch.device(0))\n",
    "        labels = labels.to(torch.device(0))\n",
    "#         img_inputs.append(inputs)\n",
    "        \n",
    "        optim_dec.zero_grad()\n",
    "        \n",
    "        img_rec_code = Dec(inputs)\n",
    "        \n",
    "        img_rec = ModelG(img_rec_code)\n",
    "        # img_rec = img_rec.view(-1, inputs.size(1), inputs.size(2), inputs.size(3))\n",
    "        # fake_labels = model(img_rec)\n",
    "        loss_rec = criterion_dec(img_rec,inputs)\n",
    "        loss_rec.backward()\n",
    "        optim_dec.step()\n",
    "        \n",
    "        del img_rec_code\n",
    "        \n",
    "        running_loss += loss_rec.item()\n",
    "        if(batch_idx % 100 == 99):\n",
    "            # print(inputs.size())\n",
    "            print('[%d, %4d] loss:%.3f'%(epoch + 1, batch_idx+1, running_loss / 100))\n",
    "            save_losses.append(running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    if(epoch % 50 == 0):\n",
    "        torch.save(Dec.state_dict(),'./dec_checkpoints/cifar10_dec_{}.pth'.format(epoch))\n",
    "        save_image(img_rec.data, './rec_img/cifar10_rec_{}.png'.format(epoch), nrow=4, normalize=True)\n",
    "        save_image(inputs.data, './rec_img/cifar10_orig_{}.png'.format(epoch), nrow=4, normalize=True)\n",
    "        img_rec_saves.append(img_rec)\n",
    "        img_inputs.append(inputs)\n",
    "#             print(score)\n",
    "    #         print(img_rec[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062\n"
     ]
    }
   ],
   "source": [
    "print(len(save_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0678948038071394"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_losses[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n",
      "  1/313 average acc 0.4062\n",
      "torch.Size([32, 3, 32, 32])\n",
      "101/313 average acc 0.3373\n",
      "torch.Size([32, 3, 32, 32])\n",
      "201/313 average acc 0.3368\n",
      "torch.Size([32, 3, 32, 32])\n",
      "301/313 average acc 0.3393\n",
      "Test Acc: 0.3400\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 0\n",
    "running_corrects = 0.0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(torch.device(0))\n",
    "    labels = labels.to(torch.device(0))\n",
    "    with torch.no_grad():\n",
    "        rec_code = Dec(inputs)\n",
    "        rec_img = ModelG(rec_code)\n",
    "        outputs = model(rec_img)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "         # statistics\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_size += inputs.size(0)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(rec_img.data.shape)\n",
    "            save_image(rec_img.data, './rec_img/test_rec_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            save_image(inputs.data, './rec_img/test_orig_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            print('{:>3}/{:>3} average acc {:.4f}\\r'.format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "            \n",
    "        del labels, outputs, preds, rec_code, rec_img\n",
    "\n",
    "test_acc = running_corrects.double() / epoch_size\n",
    "print('Test Acc: {:.4f}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Adversarial_Dataset(root_dir,'FGSM_0.2',adversarial_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    sample,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9093\n"
     ]
    }
   ],
   "source": [
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/285 average acc 0.2812\n",
      " 21/285 average acc 0.2738\n",
      " 41/285 average acc 0.2797\n",
      " 61/285 average acc 0.2772\n",
      " 81/285 average acc 0.2840\n",
      "101/285 average acc 0.2853\n",
      "121/285 average acc 0.2926\n",
      "141/285 average acc 0.2932\n",
      "161/285 average acc 0.2880\n",
      "181/285 average acc 0.2882\n",
      "201/285 average acc 0.2862\n",
      "221/285 average acc 0.2872\n",
      "241/285 average acc 0.2880\n",
      "261/285 average acc 0.2909\n",
      "281/285 average acc 0.2911\n",
      "Test Acc: 0.2917\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 0\n",
    "running_corrects = 0.0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(torch.device(0))\n",
    "    labels = labels.to(torch.device(0))\n",
    "    with torch.no_grad():\n",
    "        rec_code = Dec(inputs)\n",
    "        rec_img = ModelG(rec_code)\n",
    "        outputs = model(rec_img)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "         # statistics\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_size += inputs.size(0)\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            save_image(rec_img.data, './rec_img/test_FGSM_0.2_rec_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            save_image(inputs.data, './rec_img/test_FGSM_0.2_orig_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            print('{:>3}/{:>3} average acc {:.4f}\\r'.format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "            \n",
    "        del labels, outputs, preds, rec_code, rec_img\n",
    "\n",
    "test_acc = running_corrects.double() / epoch_size\n",
    "print('Test Acc: {:.4f}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Adversarial_Dataset(root_dir,'CW_0.2',adversarial_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    sample,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7019\n"
     ]
    }
   ],
   "source": [
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/220 average acc 0.2188\n",
      " 21/220 average acc 0.2560\n",
      " 41/220 average acc 0.2325\n",
      " 61/220 average acc 0.2387\n",
      " 81/220 average acc 0.2342\n",
      "101/220 average acc 0.2351\n",
      "121/220 average acc 0.2358\n",
      "141/220 average acc 0.2343\n",
      "161/220 average acc 0.2349\n",
      "181/220 average acc 0.2341\n",
      "201/220 average acc 0.2329\n",
      "Test Acc: 0.2308\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 0\n",
    "running_corrects = 0.0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(torch.device(0))\n",
    "    labels = labels.to(torch.device(0))\n",
    "    with torch.no_grad():\n",
    "        rec_code = Dec(inputs)\n",
    "        rec_img = ModelG(rec_code)\n",
    "        outputs = model(rec_img)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "         # statistics\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_size += inputs.size(0)\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            save_image(rec_img.data, './rec_img/test_CW_0.2_rec_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            save_image(inputs.data, './rec_img/test_CW_0.2_orig_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            print('{:>3}/{:>3} average acc {:.4f}\\r'.format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "            \n",
    "        del labels, outputs, preds, rec_code, rec_img\n",
    "\n",
    "test_acc = running_corrects.double() / epoch_size\n",
    "print('Test Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Adversarial_Dataset(root_dir,'DF_0.2',adversarial_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    sample,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357\n"
     ]
    }
   ],
   "source": [
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/199 average acc 0.3438\n",
      " 21/199 average acc 0.2113\n",
      " 41/199 average acc 0.2012\n",
      " 61/199 average acc 0.2085\n",
      " 81/199 average acc 0.2068\n",
      "101/199 average acc 0.2132\n",
      "121/199 average acc 0.2157\n",
      "141/199 average acc 0.2201\n",
      "161/199 average acc 0.2180\n",
      "181/199 average acc 0.2175\n",
      "Test Acc: 0.2185\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 0\n",
    "running_corrects = 0.0\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(torch.device(0))\n",
    "    labels = labels.to(torch.device(0))\n",
    "    with torch.no_grad():\n",
    "        rec_code = Dec(inputs)\n",
    "        rec_img = ModelG(rec_code)\n",
    "        outputs = model(rec_img)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "         # statistics\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_size += inputs.size(0)\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            save_image(rec_img.data, './rec_img/test_DF_0.2_rec_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            save_image(inputs.data, './rec_img/test_DF_0.2_orig_{}.png'.format(batch_idx), nrow=4, normalize=True)\n",
    "            print('{:>3}/{:>3} average acc {:.4f}\\r'.format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "            \n",
    "        del labels, outputs, preds, rec_code, rec_img\n",
    "\n",
    "test_acc = running_corrects.double() / epoch_size\n",
    "print('Test Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 average acc 0.1875\n",
      " 21/313 average acc 0.1949\n",
      " 41/313 average acc 0.1982\n",
      " 61/313 average acc 0.1952\n",
      " 81/313 average acc 0.1975\n",
      "101/313 average acc 0.1934\n",
      "121/313 average acc 0.1872\n",
      "141/313 average acc 0.1871\n",
      "161/313 average acc 0.1867\n",
      "181/313 average acc 0.1856\n",
      "201/313 average acc 0.1844\n",
      "221/313 average acc 0.1818\n",
      "241/313 average acc 0.1821\n",
      "261/313 average acc 0.1815\n",
      "281/313 average acc 0.1841\n",
      "301/313 average acc 0.1835\n",
      "rec_iter : 800, rec_rr : 20, Test Acc: 0.1825\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "running_corrects = 0\n",
    "epoch_size = 0\n",
    "\n",
    "is_input_size_diff = False\n",
    "\n",
    "save_test_results = []\n",
    "save_test_rec_loss = []\n",
    "\n",
    "for rec_iter in rec_iters:\n",
    "    for rec_rr in rec_rrs:\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "            # size change\n",
    "\n",
    "            if inputs.size(2) != generator_input_size :\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), generator_input_size, generator_input_size)\n",
    "\n",
    "                data = Resize_Image(target_shape, inputs)\n",
    "                data = data.to(device_generator)\n",
    "\n",
    "                is_input_size_diff = True\n",
    "\n",
    "            else :\n",
    "                data = inputs.to(device_generator)\n",
    "\n",
    "            # find z*\n",
    "\n",
    "            z_orig_sets, z_rec_sets, rec_loss = get_z_sets(ModelG, data, learning_rate, \\\n",
    "                                        device_generator, rec_iter = rec_iter, \\\n",
    "                                        rec_rr = rec_rr, input_latent = INPUT_LATENT, global_step = global_step)\n",
    "            \n",
    "            save_test_rec_loss.append(rec_loss)\n",
    "            \n",
    "            z_star = get_z_star(ModelG, data, z_rec_sets, rec_loss, device_generator, rec_rr)\n",
    "\n",
    "            # generate data\n",
    "\n",
    "            data_hat = ModelG(z_star.to(device_generator)).cpu().detach()\n",
    "            # print(data_hat)\n",
    "            # size back\n",
    "\n",
    "            if is_input_size_diff:\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), height, width)\n",
    "                data_hat = Resize_Image(target_shape, data_hat)\n",
    "\n",
    "            # classifier \n",
    "            data_hat = data_hat.to(device_model)\n",
    "\n",
    "            labels = labels.to(device_model)\n",
    "\n",
    "            # evaluate \n",
    "\n",
    "            outputs = model(data_hat)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_size += inputs.size(0)\n",
    "\n",
    "            if batch_idx % display_steps == 0:\n",
    "                save_image(data.data, './rec_img/new_lgd_L{}_R{}_orig_{}.png'.format(rec_iter,rec_rr,batch_idx), nrow=5, normalize=True)\n",
    "                save_image(data_hat.data, './rec_img/new_lgd_L{}_R{}_rec_{}.png'.format(rec_iter,rec_rr,batch_idx), nrow=5, normalize=True)\n",
    "#                 print('rec_loss: ',rec_loss)\n",
    "                print('{:>3}/{:>3} average acc {:.4f}\\r'\\\n",
    "                      .format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "\n",
    "            del labels, outputs, preds, data, data_hat,z_star\n",
    "\n",
    "        test_acc = running_corrects.double() / epoch_size\n",
    "\n",
    "        print('rec_iter : {}, rec_rr : {}, Test Acc: {:.4f}'.format(rec_iter, rec_rr, test_acc))\n",
    "        \n",
    "        save_test_results.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.1353, device='cuda:0', dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "print(save_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Adversarial_Dataset(root_dir,'FGSM_0.002',adversarial_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    sample,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "running_corrects = 0\n",
    "epoch_size = 0\n",
    "\n",
    "is_input_size_diff = False\n",
    "\n",
    "save_test_results = []\n",
    "\n",
    "for rec_iter in rec_iters:\n",
    "    for rec_rr in rec_rrs:\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "            # size change\n",
    "\n",
    "            if inputs.size(2) != generator_input_size :\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), generator_input_size, generator_input_size)\n",
    "\n",
    "                data = Resize_Image(target_shape, inputs)\n",
    "                data = data.to(device_generator)\n",
    "\n",
    "                is_input_size_diff = True\n",
    "\n",
    "            else :\n",
    "                data = inputs.to(device_generator)\n",
    "\n",
    "            # find z*\n",
    "\n",
    "            _, z_sets = get_z_sets(ModelG, data, learning_rate, \\\n",
    "                                        loss, device_generator, rec_iter = rec_iter, \\\n",
    "                                        rec_rr = rec_rr, input_latent = INPUT_LATENT, global_step = global_step)\n",
    "\n",
    "            z_star = get_z_star(ModelG, data, z_sets, loss, device_generator)\n",
    "\n",
    "            # generate data\n",
    "\n",
    "            data_hat = ModelG(z_star.to(device_generator)).cpu().detach()\n",
    "\n",
    "            # size back\n",
    "\n",
    "            if is_input_size_diff:\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), height, width)\n",
    "                data_hat = Resize_Image(target_shape, data_hat)\n",
    "\n",
    "            # classifier \n",
    "            data_hat = data_hat.to(device_model)\n",
    "\n",
    "            labels = labels.to(device_model)\n",
    "\n",
    "            # evaluate \n",
    "\n",
    "            outputs = model(data_hat)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_size += inputs.size(0)\n",
    "\n",
    "            if batch_idx % display_steps == 0:\n",
    "                print('{:>3}/{:>3} average acc {:.4f}\\r'\\\n",
    "                      .format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "\n",
    "            del labels, outputs, preds, data, data_hat,z_star\n",
    "\n",
    "        test_acc = running_corrects.double() / epoch_size\n",
    "\n",
    "        print('rec_iter : {}, rec_rr : {}, Test Acc: {:.4f}'.format(rec_iter, rec_rr, test_acc))\n",
    "        \n",
    "        save_test_results.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Adversarial_Dataset(root_dir,'CW_0.2',adversarial_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    sample,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Fool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Adversarial_Dataset(root_dir,'DF_0.002',adversarial_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    sample,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "running_corrects = 0\n",
    "epoch_size = 0\n",
    "\n",
    "is_input_size_diff = False\n",
    "\n",
    "save_test_results = []\n",
    "\n",
    "for rec_iter in rec_iters:\n",
    "    for rec_rr in rec_rrs:\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "            # size change\n",
    "\n",
    "            if inputs.size(2) != generator_input_size :\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), generator_input_size, generator_input_size)\n",
    "\n",
    "                data = Resize_Image(target_shape, inputs)\n",
    "                data = data.to(device_generator)\n",
    "\n",
    "                is_input_size_diff = True\n",
    "\n",
    "            else :\n",
    "                data = inputs.to(device_generator)\n",
    "\n",
    "            # find z*\n",
    "\n",
    "            _, z_sets = get_z_sets(ModelG, data, learning_rate, \\\n",
    "                                        loss, device_generator, rec_iter = rec_iter, \\\n",
    "                                        rec_rr = rec_rr, input_latent = INPUT_LATENT, global_step = global_step)\n",
    "\n",
    "            z_star = get_z_star(ModelG, data, z_sets, loss, device_generator)\n",
    "\n",
    "            # generate data\n",
    "\n",
    "            data_hat = ModelG(z_star.to(device_generator)).cpu().detach()\n",
    "\n",
    "            # size back\n",
    "\n",
    "            if is_input_size_diff:\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), height, width)\n",
    "                data_hat = Resize_Image(target_shape, data_hat)\n",
    "\n",
    "            # classifier \n",
    "            data_hat = data_hat.to(device_model)\n",
    "\n",
    "            labels = labels.to(device_model)\n",
    "\n",
    "            # evaluate \n",
    "\n",
    "            outputs = model(data_hat)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_size += inputs.size(0)\n",
    "\n",
    "            if batch_idx % display_steps == 0:\n",
    "                print('{:>3}/{:>3} average acc {:.4f}\\r'\\\n",
    "                      .format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "\n",
    "            del labels, outputs, preds, data, data_hat,z_star\n",
    "\n",
    "        test_acc = running_corrects.double() / epoch_size\n",
    "\n",
    "        print('rec_iter : {}, rec_rr : {}, Test Acc: {:.4f}'.format(rec_iter, rec_rr, test_acc))\n",
    "        \n",
    "        save_test_results.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Adversarial_Dataset(root_dir,'SM',adversarial_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    sample,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "running_corrects = 0\n",
    "epoch_size = 0\n",
    "\n",
    "is_input_size_diff = False\n",
    "\n",
    "save_test_results = []\n",
    "\n",
    "for rec_iter in rec_iters:\n",
    "    for rec_rr in rec_rrs:\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "            # size change\n",
    "\n",
    "            if inputs.size(2) != generator_input_size :\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), generator_input_size, generator_input_size)\n",
    "\n",
    "                data = Resize_Image(target_shape, inputs)\n",
    "                data = data.to(device_generator)\n",
    "\n",
    "                is_input_size_diff = True\n",
    "\n",
    "            else :\n",
    "                data = inputs.to(device_generator)\n",
    "\n",
    "            # find z*\n",
    "\n",
    "            _, z_sets = get_z_sets(ModelG, data, learning_rate, \\\n",
    "                                        loss, device_generator, rec_iter = rec_iter, \\\n",
    "                                        rec_rr = rec_rr, input_latent = INPUT_LATENT, global_step = global_step)\n",
    "\n",
    "            z_star = get_z_star(ModelG, data, z_sets, loss, device_generator)\n",
    "\n",
    "            # generate data\n",
    "\n",
    "            data_hat = ModelG(z_star.to(device_generator)).cpu().detach()\n",
    "\n",
    "            # size back\n",
    "\n",
    "            if is_input_size_diff:\n",
    "\n",
    "                target_shape = (inputs.size(0), inputs.size(1), height, width)\n",
    "                data_hat = Resize_Image(target_shape, data_hat)\n",
    "\n",
    "            # classifier \n",
    "            data_hat = data_hat.to(device_model)\n",
    "\n",
    "            labels = labels.to(device_model)\n",
    "\n",
    "            # evaluate \n",
    "\n",
    "            outputs = model(data_hat)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_size += inputs.size(0)\n",
    "\n",
    "            if batch_idx % display_steps == 0:\n",
    "                print('{:>3}/{:>3} average acc {:.4f}\\r'\\\n",
    "                      .format(batch_idx+1, len(test_loader), running_corrects.double() / epoch_size))\n",
    "\n",
    "            del labels, outputs, preds, data, data_hat,z_star\n",
    "\n",
    "        test_acc = running_corrects.double() / epoch_size\n",
    "\n",
    "        print('rec_iter : {}, rec_rr : {}, Test Acc: {:.4f}'.format(rec_iter, rec_rr, test_acc))\n",
    "        \n",
    "        save_test_results.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pg",
   "language": "python",
   "name": "pg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
